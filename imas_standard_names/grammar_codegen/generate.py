"""Generate code (types + metadata) from ``grammar.yml`` and ``tags.yml``.

Outputs:
- ``imas_standard_names/grammar/types.py``
- ``imas_standard_names/grammar/tag_types.py``

Lives outside the ``grammar`` package to avoid importing any module that
depends on the generated file during generation.
"""

from __future__ import annotations

from collections.abc import Mapping
from pathlib import Path
from textwrap import dedent, indent
from typing import Any

from imas_standard_names.grammar_codegen.spec import GrammarSpec
from imas_standard_names.grammar_codegen.tag_spec import TagSpec

HEADER = (
    "Auto-generated grammar models.\n\n"
    "This file was generated by "
    "imas_standard_names.grammar_codegen.generate\n"
    "from imas_standard_names/grammar/specification.yml. Do not edit manually."
)

TAG_HEADER = (
    "Auto-generated tag models.\n\n"
    "This file was generated by "
    "imas_standard_names.grammar_codegen.generate\n"
    "from imas_standard_names/grammar/vocabularies/tags.yml. Do not edit manually."
)

# The output is next to the runtime grammar modules
OUTPUT_MODULE = Path(__file__).resolve().parents[1] / "grammar" / "types.py"
TAG_OUTPUT_MODULE = Path(__file__).resolve().parents[1] / "grammar" / "tag_types.py"

ENUM_NAME_OVERRIDES = {
    "components": "Component",
    "subjects": "Subject",
    "basis": "Basis",
    "objects": "Object",
    "sources": "Source",
    "positions": "Position",
    "processes": "Process",
}


def main() -> None:
    # Generate grammar types
    spec = GrammarSpec.load()
    content = render_module(spec)
    existing = (
        OUTPUT_MODULE.read_text(encoding="utf-8") if OUTPUT_MODULE.exists() else ""
    )
    grammar_updated = False
    if existing != content:
        OUTPUT_MODULE.parent.mkdir(parents=True, exist_ok=True)
        OUTPUT_MODULE.write_text(content, encoding="utf-8")
        print("Updated grammar/types.py")
        grammar_updated = True
    else:
        print("grammar/types.py already up to date")

    # Generate tag types
    tag_spec = TagSpec.load()
    tag_content = render_tag_module(tag_spec)
    tag_existing = (
        TAG_OUTPUT_MODULE.read_text(encoding="utf-8")
        if TAG_OUTPUT_MODULE.exists()
        else ""
    )
    tags_updated = False
    if tag_existing != tag_content:
        TAG_OUTPUT_MODULE.parent.mkdir(parents=True, exist_ok=True)
        TAG_OUTPUT_MODULE.write_text(tag_content, encoding="utf-8")
        print("Updated grammar/tag_types.py")
        tags_updated = True
    else:
        print("grammar/tag_types.py already up to date")

    if not grammar_updated and not tags_updated:
        print("All generated files up to date")


def render_module(spec: Any) -> str:
    metadata = _segment_metadata(spec)
    sections = [
        _module_header(),
        _import_block(),
        _enum_definitions(spec),
        _segment_rule_dataclass(),
        _render_segment_metadata(metadata),
        _render_scope_metadata(spec),
        _export_block(spec),
    ]

    parts: list[str] = []
    previous_index: int | None = None
    for idx, section in enumerate(sections):
        if not section:
            continue
        text = section.strip()
        if not text:
            continue
        if parts:
            separator = "\n\n"
            if previous_index == 1:
                separator = "\n\n\n"
            parts.append(separator)
        parts.append(text)
        previous_index = idx

    body = "".join(parts)
    return f"{body}\n"


def _module_header() -> str:
    return f'"""{HEADER.strip()}"""'


def _import_block() -> str:
    return dedent(
        """
from __future__ import annotations

from collections.abc import Mapping
from dataclasses import dataclass
from enum import StrEnum
        """
    ).strip()


def _segment_rule_dataclass() -> str:
    return dedent(
        """
        @dataclass(frozen=True)
        class SegmentRule:
            identifier: str
            optional: bool
            template: str | None
            exclusive_with: tuple[str, ...]
            tokens: tuple[str, ...]
        """
    ).strip()


def _enum_definitions(spec: Any) -> str:
    blocks: list[str] = []
    for vocab_name, tokens in spec.vocabularies.items():
        enum_name = _enum_class_name(vocab_name)
        lines = [f"class {enum_name}(StrEnum):"]
        if not tokens:
            lines.append("    pass")
        else:
            for token in tokens:
                member = _enum_member_name(token)
                lines.append(f'    {member} = "{token}"')
        blocks.append("\n".join(lines))
    return "\n\n".join(blocks)


def _segment_metadata(spec: Any) -> dict[str, Any]:
    segment_rules: list[dict[str, Any]] = []
    for segment in spec.segments:
        segment_rules.append(
            {
                "identifier": segment.identifier,
                "optional": segment.optional,
                "template": segment.template,
                "exclusive_with": tuple(segment.exclusive_with),
            }
        )

    segment_order = tuple(segment.identifier for segment in spec.segments)

    segment_templates = {
        segment.identifier: segment.template
        for segment in spec.segments
        if segment.template
    }

    segment_token_map = {
        segment.identifier: tuple(spec.tokens_for_segment(segment.identifier))
        for segment in spec.segments
    }

    segment_enum_map = {
        segment.identifier: (
            _enum_class_name(segment.vocabulary_name)
            if segment.vocabulary_name
            else None
        )
        for segment in spec.segments
    }

    exclusive_pairs = sorted(
        {
            tuple(sorted((segment.identifier, other)))
            for segment in spec.segments
            for other in segment.exclusive_with
        }
    )

    return {
        "segment_rules": tuple(segment_rules),
        "segment_order": segment_order,
        "segment_templates": segment_templates,
        "segment_token_map": segment_token_map,
        "segment_enum_map": segment_enum_map,
        "exclusive_pairs": tuple(tuple(pair) for pair in exclusive_pairs),
    }


def _render_segment_metadata(meta: Mapping[str, Any]) -> str:
    token_map_lines: list[str] = ["SEGMENT_TOKEN_MAP: dict[str, tuple[str, ...]] = {"]
    segment_enum_map: Mapping[str, str | None] = meta["segment_enum_map"]
    for identifier, tokens in meta["segment_token_map"].items():
        enum_name = segment_enum_map.get(identifier)
        if enum_name:
            value_expr = f"tuple(member.value for member in {enum_name})"
            token_map_lines.append(f"    '{identifier}': {value_expr},")
            continue

        if tokens:
            tuple_repr = _format_tuple_literal(tokens, indent=8, base_indent=4)
            token_map_lines.append(f"    '{identifier}': {tuple_repr},")
        else:
            token_map_lines.append(f"    '{identifier}': (),")
    token_map_lines.append("}")
    token_map_repr = "\n".join(token_map_lines)
    order_repr = _format_tuple_literal(meta["segment_order"], indent=4, base_indent=0)
    template_map_repr = _format_str_dict_literal(meta["segment_templates"])
    exclusive_repr = _format_tuple_literal(
        meta["exclusive_pairs"], indent=4, base_indent=0
    )

    rule_blocks: list[str] = []
    for entry in meta["segment_rules"]:
        template_repr = (
            repr(entry["template"]) if entry["template"] is not None else "None"
        )
        block = dedent(
            f"""
            SegmentRule(
                identifier='{entry["identifier"]}',
                optional={entry["optional"]},
                template={template_repr},
                exclusive_with={entry["exclusive_with"]},
                tokens=SEGMENT_TOKEN_MAP['{entry["identifier"]}'],
            ),
            """
        ).strip()
        rule_blocks.append(indent(block, "    "))

    rules_section = "\n".join(rule_blocks)
    prefix_suffix_block = dedent(
        """
        _PREFIX_END = SEGMENT_ORDER.index('base')
        PREFIX_SEGMENTS: tuple[str, ...] = SEGMENT_ORDER[:_PREFIX_END]
        SUFFIX_SEGMENTS: tuple[str, ...] = SEGMENT_ORDER[_PREFIX_END + 1 :]
        SUFFIX_SEGMENTS_REVERSED: tuple[str, ...] = tuple(reversed(SUFFIX_SEGMENTS))
        """
    ).strip()

    token_search_block = dedent(
        """
        SEGMENT_SEARCH_TOKEN_MAP: dict[str, tuple[str, ...]] = {
            key: tuple(sorted(tokens, key=len, reverse=True))
            for key, tokens in SEGMENT_TOKEN_MAP.items()
        }
        SEGMENT_PREFIX_TOKEN_MAP: Mapping[str, tuple[str, ...]] = SEGMENT_SEARCH_TOKEN_MAP
        SEGMENT_SUFFIX_TOKEN_MAP: Mapping[str, tuple[str, ...]] = SEGMENT_SEARCH_TOKEN_MAP
        """
    ).strip()

    sections = [
        token_map_repr,
        dedent(
            """
            SEGMENT_RULES: tuple[SegmentRule, ...] = (
            {rules_block}
            )
            """
        )
        .format(rules_block=rules_section)
        .strip(),
        f"SEGMENT_ORDER: tuple[str, ...] = {order_repr}",
        prefix_suffix_block,
        f"SEGMENT_TEMPLATES: dict[str, str] = {template_map_repr}",
        token_search_block,
        f"EXCLUSIVE_SEGMENT_PAIRS: tuple[tuple[str, str], ...] = {exclusive_repr}",
    ]

    return "\n\n".join(section for section in sections if section)


def _render_scope_metadata(spec: Any) -> str:
    """Render scope metadata (when to create standard names)."""
    if not spec.scope:
        return ""

    include_repr = _format_tuple_literal(spec.scope.include, indent=4, base_indent=0)
    exclude_repr = _format_tuple_literal(spec.scope.exclude, indent=4, base_indent=0)
    rationale_repr = repr(spec.scope.rationale)

    return (
        "# Scope: when to create standard names\n"
        f"SCOPE_INCLUDE: tuple[str, ...] = {include_repr}\n"
        f"SCOPE_EXCLUDE: tuple[str, ...] = {exclude_repr}\n"
        f"SCOPE_RATIONALE: str = {rationale_repr}"
    )


def _export_block(spec: Any) -> str:
    names = [_enum_class_name(name) for name in spec.vocabularies]
    formatted = ",\n    ".join(f"'{name}'" for name in names)
    return "__all__ = [\n    " + formatted + "\n]"


def _format_tuple_literal(
    values: list[Any] | tuple[Any, ...], indent: int, base_indent: int
) -> str:
    items = list(values)
    if not items:
        return "()"
    element_indent = " " * indent
    closing_indent = " " * base_indent
    lines = [f"{element_indent}{repr(item)}," for item in items]
    return "(\n" + "\n".join(lines) + f"\n{closing_indent})"


def _format_str_dict_literal(mapping: Mapping[str, str]) -> str:
    if not mapping:
        return "{}"
    lines = ["{"]
    for key, value in mapping.items():
        lines.append(f"    '{key}': '{value}',")
    lines.append("}")
    return "\n".join(lines)


def _enum_member_name(token: str) -> str:
    return token.upper()


def _pascal_case(text: str) -> str:
    return "".join(part.capitalize() for part in text.split("_"))


def _singularize(name: str) -> str:
    if name.endswith("ies"):
        return name[:-3] + "y"
    if name.endswith("ses"):
        return name[:-2]
    if name.endswith("s"):
        return name[:-1]
    return name


def _enum_class_name(vocab_name: str) -> str:
    override = ENUM_NAME_OVERRIDES.get(vocab_name)
    if override:
        return override
    return _pascal_case(_singularize(vocab_name))


# ============================================================================
# Tag Type Generation
# ============================================================================


def render_tag_module(spec: TagSpec) -> str:
    """Render the tag_types.py module from TagSpec."""
    sections = [
        _tag_module_header(),
        _tag_import_block(),
        _tag_literal_types(spec),
        _tag_metadata(spec),
        _tag_export_block(),
    ]

    parts: list[str] = []
    for section in sections:
        if not section:
            continue
        text = section.strip()
        if not text:
            continue
        if parts:
            parts.append("\n\n")
        parts.append(text)

    body = "".join(parts)
    return f"{body}\n"


def _tag_module_header() -> str:
    return f'"""{TAG_HEADER.strip()}"""'


def _tag_import_block() -> str:
    return dedent(
        """
        from __future__ import annotations

        from typing import Literal
        """
    ).strip()


def _tag_literal_types(spec: TagSpec) -> str:
    """Generate Literal type aliases for primary and secondary tags."""
    primary_values = ", ".join(f'"{tag}"' for tag in spec.primary_tags)
    secondary_values = ", ".join(f'"{tag}"' for tag in spec.secondary_tags)

    return dedent(
        f"""
        # Primary tags define catalog subdirectory organization (tags[0])
        PrimaryTag = Literal[{primary_values}]

        # Secondary tags provide cross-cutting classification (tags[1:])
        SecondaryTag = Literal[{secondary_values}]

        # Union type for any tag
        Tag = PrimaryTag | SecondaryTag
        """
    ).strip()


def _tag_metadata(spec: TagSpec) -> str:
    """Generate metadata constants for tag descriptions and examples."""
    # Primary tag descriptions
    primary_desc_lines = ["PRIMARY_TAG_DESCRIPTIONS: dict[str, str] = {"]
    for tag_id in spec.primary_tags:
        meta = spec.primary_metadata.get(tag_id, {})
        description = meta.get("description", "")
        primary_desc_lines.append(f"    '{tag_id}': '{description}',")
    primary_desc_lines.append("}")
    primary_desc_block = "\n".join(primary_desc_lines)

    # Secondary tag descriptions
    secondary_desc_lines = ["SECONDARY_TAG_DESCRIPTIONS: dict[str, str] = {"]
    for tag_id in spec.secondary_tags:
        meta = spec.secondary_metadata.get(tag_id, {})
        description = meta.get("description", "")
        secondary_desc_lines.append(f"    '{tag_id}': '{description}',")
    secondary_desc_lines.append("}")
    secondary_desc_block = "\n".join(secondary_desc_lines)

    # All tags tuple for validation
    primary_tuple = _format_tuple_literal(spec.primary_tags, indent=4, base_indent=0)
    secondary_tuple = _format_tuple_literal(
        spec.secondary_tags, indent=4, base_indent=0
    )

    return (
        f"{primary_desc_block}\n\n"
        f"{secondary_desc_block}\n\n"
        f"PRIMARY_TAGS: tuple[str, ...] = {primary_tuple}\n\n"
        f"SECONDARY_TAGS: tuple[str, ...] = {secondary_tuple}"
    )


def _tag_export_block() -> str:
    return dedent(
        """
        __all__ = [
            'PrimaryTag',
            'SecondaryTag',
            'Tag',
            'PRIMARY_TAGS',
            'SECONDARY_TAGS',
            'PRIMARY_TAG_DESCRIPTIONS',
            'SECONDARY_TAG_DESCRIPTIONS',
        ]
        """
    ).strip()


if __name__ == "__main__":
    main()
